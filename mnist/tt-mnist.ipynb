{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tntorch as tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_dot(in_modes, out_modes, ranks, inputs, weight, bias=None) :\n",
    "    \"according to TGaripov repo\"\n",
    "    res = inputs\n",
    "    res = res.view(-1, int(np.prod(in_modes)))\n",
    "    res = res.transpose(1, 0)\n",
    "    res = res.contiguous()\n",
    "    dim = len(in_modes)\n",
    "    for ii in range(dim) :\n",
    "        res = res.view(ranks[ii] * in_modes[ii], -1)\n",
    "        res = torch.matmul(weight[ii], res)\n",
    "        res = res.view(out_modes[ii], -1)\n",
    "        res = res.transpose(1, 0)\n",
    "        res = res.contiguous()\n",
    "    res = res.view(-1, int(np.prod(out_modes)))\n",
    "\n",
    "    if bias is not None :\n",
    "        res += bias\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTLayer(nn.Module):\n",
    "    def __init__(self, in_modes, out_modes, ranks, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_modes = in_modes\n",
    "        self.out_modes = out_modes\n",
    "        self.ranks = ranks\n",
    "        dim = len(self.in_modes)\n",
    "\n",
    "        assert len(self.in_modes) == len(self.out_modes) == len(self.ranks)-1\n",
    "        \n",
    "        self.weight = self._create_tt_cores(self.in_modes, self.out_modes, self.ranks)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(np.prod(out_modes)))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_normal(self) :\n",
    "        normal_z = ((((0.05**2)/np.prod(self.ranks)))**(1/(len(self.ranks)-1))) ** 0.5 \n",
    "        for i in range(len(self.weight)) :\n",
    "            nn.init.normal_(self.weight[i], 0, normal_z)\n",
    "\n",
    "    def reset_parameters(self) :\n",
    "        self.reset_normal()\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return tt_dot(self.in_modes, self.out_modes, self.ranks, input, self.weight, self.bias)\n",
    "\n",
    "    def _create_tt_cores(self, in_modes, out_modes, ranks):\n",
    "        \"\"\"\n",
    "        in_modes: shape of initial tensor\n",
    "        out_modes: shape of out tensor \n",
    "        Total tensor shape is element_wise_product(in_modes,out_modes)\n",
    "        ranks: desirable ranks of tt\n",
    "        return: weights\n",
    "        \"\"\"\n",
    "        dim = len(in_modes)\n",
    "        _tt_cores_list = []\n",
    "\n",
    "        for i in range(dim) :\n",
    "            _tt_cores_list.append(nn.Parameter(torch.Tensor(out_modes[i] * ranks[i+1], in_modes[i] * ranks[i])))\n",
    "\n",
    "        weight = nn.ParameterList(_tt_cores_list)\n",
    "        return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# in_modes = [2,14,14,2]\n",
    "# out_modes = [2,8,8,2]\n",
    "ranks = [1,2,4,2,1]\n",
    "in_modes = [7,4,7,4]\n",
    "# out_modes = [5,5,5,5]\n",
    "out_modes = [2,8,8,2]\n",
    "tt_ranks = [1,2,4,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, compress=False, in_modes=None, out_modes=None, ranks=None):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        if compress:\n",
    "            self.fc1 = TTLayer(in_modes, out_modes, ranks)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_model_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tt = NeuralNet(input_size, hidden_size, num_classes, True, in_modes, out_modes, tt_ranks).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.94739787353106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_model_params(NeuralNet(input_size, hidden_size, num_classes).to(device))/num_model_params(model_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, train_loader, criterion, optimizer):\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images.double())\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images.double())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 1.0074\n",
      "Epoch [1/5], Step [200/600], Loss: 0.7649\n",
      "Epoch [1/5], Step [300/600], Loss: 0.3654\n",
      "Epoch [1/5], Step [400/600], Loss: 0.5241\n",
      "Epoch [1/5], Step [500/600], Loss: 0.4166\n",
      "Epoch [1/5], Step [600/600], Loss: 0.4175\n",
      "Epoch [2/5], Step [100/600], Loss: 0.3205\n",
      "Epoch [2/5], Step [200/600], Loss: 0.2854\n",
      "Epoch [2/5], Step [300/600], Loss: 0.3477\n",
      "Epoch [2/5], Step [400/600], Loss: 0.3505\n",
      "Epoch [2/5], Step [500/600], Loss: 0.2539\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1879\n",
      "Epoch [3/5], Step [100/600], Loss: 0.2152\n",
      "Epoch [3/5], Step [200/600], Loss: 0.2725\n",
      "Epoch [3/5], Step [300/600], Loss: 0.3695\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1758\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1589\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0707\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0773\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1279\n",
      "Epoch [4/5], Step [300/600], Loss: 0.2271\n",
      "Epoch [4/5], Step [400/600], Loss: 0.1459\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0765\n",
      "Epoch [4/5], Step [600/600], Loss: 0.1293\n",
      "Epoch [5/5], Step [100/600], Loss: 0.2302\n",
      "Epoch [5/5], Step [200/600], Loss: 0.1949\n",
      "Epoch [5/5], Step [300/600], Loss: 0.2879\n",
      "Epoch [5/5], Step [400/600], Loss: 0.1499\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0771\n",
      "Epoch [5/5], Step [600/600], Loss: 0.1403\n"
     ]
    }
   ],
   "source": [
    "model_tt = NeuralNet(input_size, hidden_size, num_classes, True, in_modes, out_modes, tt_ranks).to(device)\n",
    "criterion_tt = nn.CrossEntropyLoss()\n",
    "optimizer_tt = torch.optim.Adam(model_tt.parameters(), lr=learning_rate)  \n",
    "\n",
    "model_tt = train_nn(model_tt, train_loader,criterion_tt, optimizer_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3275\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1984\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2375\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2280\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1115\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1821\n",
      "Epoch [2/5], Step [100/600], Loss: 0.2358\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1317\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0862\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1457\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1399\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0963\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0584\n",
      "Epoch [3/5], Step [200/600], Loss: 0.2307\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1082\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1430\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0660\n",
      "Epoch [3/5], Step [600/600], Loss: 0.1182\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0328\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1310\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0527\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0745\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0612\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0470\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0225\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0816\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0654\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0766\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0843\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0521\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes, compress=False).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "model = train_nn(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.43 %\n",
      "Accuracy of the network on the 10000 test images: 97.49 %\n",
      "Compression rate: 56.94739787353106\n"
     ]
    }
   ],
   "source": [
    "test_model(model_tt, test_loader)\n",
    "test_model(model, test_loader)\n",
    "print(\"Compression rate: {}\".format(num_model_params(model)/num_model_params(model_tt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.DoubleTensor of size 4x7]\n",
       "    (1): Parameter containing: [torch.DoubleTensor of size 32x8]\n",
       "    (2): Parameter containing: [torch.DoubleTensor of size 16x28]\n",
       "    (3): Parameter containing: [torch.DoubleTensor of size 2x8]\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tt.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_original = model.fc1.weight.data\n",
    "\n",
    "w1_reshaped = w1_original.view(list(np.array(in_modes)*np.array(out_modes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_w1 = tnt.Tensor(w1_reshaped, ranks_tt=tt_ranks[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(t, full):\n",
    "    print(t)\n",
    "    print('Compression ratio: {}/{} = {:g}'.format(full.numel(), t.numel(), full.numel() / t.numel()))\n",
    "    print('Relative error:', tnt.relative_error(full, t))\n",
    "    print('RMSE:', tnt.rmse(full, t))\n",
    "    print('R^2:', tnt.r_squared(full, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D TT tensor:\n",
      "\n",
      " 14  32  56   8\n",
      "  |   |   |   |\n",
      " (0) (1) (2) (3)\n",
      " / \\ / \\ / \\ / \\\n",
      "1   2   4   2   1\n",
      "\n",
      "Compression ratio: 200704/748 = 268.321\n",
      "Relative error: tensor(0.9790)\n",
      "RMSE: tensor(0.0712)\n",
      "R^2: tensor(0.0416)\n"
     ]
    }
   ],
   "source": [
    "metrics(tt_w1, w1_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_cores = tt_w1.cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([16, 28])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([1, 14, 2])\n",
      "torch.Size([2, 32, 4])\n",
      "torch.Size([4, 56, 2])\n",
      "torch.Size([2, 8, 1])\n",
      "==========\n",
      "torch.Size([4, 7])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([16, 28])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "model_tt = NeuralNet(input_size, hidden_size, num_classes, True, in_modes, out_modes, tt_w1.ranks_tt).to(device)\n",
    "\n",
    "\n",
    "params = []\n",
    "\n",
    "for child  in model_tt.fc1.children():\n",
    "    for param in list(child.parameters()):\n",
    "        params.append(param)\n",
    "        print(param.size())\n",
    "        \n",
    "reshaped_cores = []\n",
    "\n",
    "for w,p in zip(w1_cores, params):\n",
    "    print(w.size())\n",
    "    reshaped_cores.append(w.view_as(p))\n",
    "        \n",
    "print(\"=\"*10)\n",
    "\n",
    "new_params = []\n",
    "for m,p in zip(w1_cores,params):\n",
    "    print(m.view_as(p).size())\n",
    "    new_params.append(m.view_as(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, n_p in zip(model_tt.fc1.weight.parameters(), new_params):\n",
    "    p.data.copy_(n_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 5.88 %\n",
      "Accuracy of the network on the 10000 test images: 97.49 %\n",
      "Compression rate: 56.94739787353106\n"
     ]
    }
   ],
   "source": [
    "test_model(model_tt, test_loader)\n",
    "test_model(model, test_loader)\n",
    "print(\"Compression rate: {}\".format(num_model_params(model)/num_model_params(model_tt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
